{"cells":[{"cell_type":"code","execution_count":128,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-12-15T01:32:25.309114Z","iopub.status.busy":"2023-12-15T01:32:25.308701Z","iopub.status.idle":"2023-12-15T01:32:25.319613Z","shell.execute_reply":"2023-12-15T01:32:25.318746Z","shell.execute_reply.started":"2023-12-15T01:32:25.309084Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os\n","import tensorflow as tf\n","from tqdm import tqdm\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.utils import Sequence\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Activation, Dropout, Flatten, Dense, Input, Layer\n","from tensorflow.keras.layers import Embedding, LSTM, add, Concatenate, Reshape, concatenate, Bidirectional\n","from tensorflow.keras.applications import VGG16, ResNet50, DenseNet201\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n","from sklearn.model_selection import train_test_split\n","import warnings\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from textwrap import wrap\n","import re\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","import pandas as pd\n","import nltk\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","from keras.applications.resnet50 import ResNet50, preprocess_input\n","\n","\n","plt.rcParams['font.size'] = 12\n","sns.set_style(\"dark\")\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":129,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T01:32:27.017956Z","iopub.status.busy":"2023-12-15T01:32:27.017105Z","iopub.status.idle":"2023-12-15T01:32:27.022048Z","shell.execute_reply":"2023-12-15T01:32:27.021137Z","shell.execute_reply.started":"2023-12-15T01:32:27.017916Z"},"trusted":true},"outputs":[],"source":["image_path = '/kaggle/input/flickr30k/flickr30k_images/'"]},{"cell_type":"code","execution_count":130,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T01:32:27.396311Z","iopub.status.busy":"2023-12-15T01:32:27.395287Z","iopub.status.idle":"2023-12-15T01:32:27.625294Z","shell.execute_reply":"2023-12-15T01:32:27.624468Z","shell.execute_reply.started":"2023-12-15T01:32:27.396236Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image_name</th>\n","      <th>comment_number</th>\n","      <th>comment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1000092795.jpg</td>\n","      <td>0</td>\n","      <td>Two young guys with shaggy hair look at their ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1000092795.jpg</td>\n","      <td>1</td>\n","      <td>Two young  White males are outside near many b...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1000092795.jpg</td>\n","      <td>2</td>\n","      <td>Two men in green shirts are standing in a yard .</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1000092795.jpg</td>\n","      <td>3</td>\n","      <td>A man in a blue shirt standing in a garden .</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1000092795.jpg</td>\n","      <td>4</td>\n","      <td>Two friends enjoy time spent together .</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       image_name  comment_number  \\\n","0  1000092795.jpg               0   \n","1  1000092795.jpg               1   \n","2  1000092795.jpg               2   \n","3  1000092795.jpg               3   \n","4  1000092795.jpg               4   \n","\n","                                             comment  \n","0  Two young guys with shaggy hair look at their ...  \n","1  Two young  White males are outside near many b...  \n","2   Two men in green shirts are standing in a yard .  \n","3       A man in a blue shirt standing in a garden .  \n","4            Two friends enjoy time spent together .  "]},"execution_count":130,"metadata":{},"output_type":"execute_result"}],"source":["data = pd.read_csv(\"/kaggle/input/flickr30k/captions.txt\")\n","data.head()"]},{"cell_type":"code","execution_count":131,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T01:32:27.827788Z","iopub.status.busy":"2023-12-15T01:32:27.826844Z","iopub.status.idle":"2023-12-15T01:32:27.837035Z","shell.execute_reply":"2023-12-15T01:32:27.836138Z","shell.execute_reply.started":"2023-12-15T01:32:27.827737Z"},"trusted":true},"outputs":[],"source":["def readImage(path,img_size=224):\n","    img = load_img(path,color_mode='rgb',target_size=(img_size,img_size))\n","    img = img_to_array(img)\n","    img = img/255.\n","    \n","    return img\n"]},{"cell_type":"code","execution_count":133,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T01:32:31.675585Z","iopub.status.busy":"2023-12-15T01:32:31.675067Z","iopub.status.idle":"2023-12-15T01:32:31.685004Z","shell.execute_reply":"2023-12-15T01:32:31.684165Z","shell.execute_reply.started":"2023-12-15T01:32:31.675535Z"},"trusted":true},"outputs":[],"source":["def text_preprocessing(data):\n","    lemmatizer = WordNetLemmatizer()\n","    stop_words = set(stopwords.words('english'))\n","\n","    for i in range(len(data)):\n","        text = data.loc[i, 'comment']\n","        text = text.lower()\n","        text = re.sub(\"[^a-z\\s]\", \"\", text)\n","        text = re.sub(\"\\s+\", \" \", text)\n","        text = \" \".join([lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words and len(word) > 1])\n","\n","        data.loc[i, 'comment'] = \"startseq \" + text + \" endseq\"\n","\n","    return data"]},{"cell_type":"markdown","metadata":{},"source":["## __Preprocessed Text__"]},{"cell_type":"code","execution_count":134,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T01:32:32.545273Z","iopub.status.busy":"2023-12-15T01:32:32.544410Z","iopub.status.idle":"2023-12-15T01:32:33.392290Z","shell.execute_reply":"2023-12-15T01:32:33.391310Z","shell.execute_reply.started":"2023-12-15T01:32:32.545219Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['startseq two young guys with shaggy hair look at their hands while hanging out in the yard endseq',\n"," 'startseq two young white males are outside near many bushes endseq',\n"," 'startseq two men in green shirts are standing in yard endseq',\n"," 'startseq man in blue shirt standing in garden endseq',\n"," 'startseq two friends enjoy time spent together endseq',\n"," 'startseq several men in hard hats are operating giant pulley system endseq',\n"," 'startseq workers look down from up above on piece of equipment endseq',\n"," 'startseq two men working on machine wearing hard hats endseq',\n"," 'startseq four men on top of tall structure endseq',\n"," 'startseq three men on large rig endseq']"]},"execution_count":134,"metadata":{},"output_type":"execute_result"}],"source":["data = text_preprocessing(data)\n","captions = data['comment'].tolist()\n","captions[:10]"]},{"cell_type":"code","execution_count":184,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T03:49:05.829525Z","iopub.status.busy":"2023-12-15T03:49:05.829006Z","iopub.status.idle":"2023-12-15T03:49:09.102282Z","shell.execute_reply":"2023-12-15T03:49:09.101455Z","shell.execute_reply.started":"2023-12-15T03:49:05.829487Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[1, 12, 21, 20, 708, 13, 54, 79, 194, 1421, 2]"]},"execution_count":184,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(captions)\n","vocab_size = len(tokenizer.word_index) + 1\n","max_length = max(len(caption.split()) for caption in captions)\n","\n","images = data['image_name'].unique().tolist()\n","\n","train_images, val_images = train_test_split(images, test_size=0.15, shuffle=True)\n","\n","train = data[data['image_name'].isin(train_images)]\n","test = data[data['image_name'].isin(val_images)]\n","\n","train.reset_index(inplace=True,drop=True)\n","test.reset_index(inplace=True,drop=True)\n","\n","tokenizer.texts_to_sequences([captions[1]])[0]"]},{"cell_type":"code","execution_count":136,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T01:32:39.168720Z","iopub.status.busy":"2023-12-15T01:32:39.168314Z","iopub.status.idle":"2023-12-15T01:32:39.174357Z","shell.execute_reply":"2023-12-15T01:32:39.173593Z","shell.execute_reply.started":"2023-12-15T01:32:39.168682Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(135080, 3)"]},"execution_count":136,"metadata":{},"output_type":"execute_result"}],"source":["train.shape"]},{"cell_type":"code","execution_count":137,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T01:32:39.175826Z","iopub.status.busy":"2023-12-15T01:32:39.175420Z","iopub.status.idle":"2023-12-15T02:17:43.166785Z","shell.execute_reply":"2023-12-15T02:17:43.165911Z","shell.execute_reply.started":"2023-12-15T01:32:39.175799Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 31783/31783 [44:59<00:00, 11.77it/s]  \n"]}],"source":["model = ResNet50(weights='imagenet', include_top=False)\n","fe = Model(inputs=model.input, outputs=model.layers[-2].output)\n","img_size = 224\n","features = {}\n","for image in tqdm(data['image_name'].unique().tolist()):\n","    img_path = os.path.join(image_path, image)  \n","    img = load_img(img_path, target_size=(img_size, img_size))\n","    img = img_to_array(img)\n","    img = preprocess_input(img)  \n","    img = np.expand_dims(img, axis=0)\n","    feature = fe.predict(img, verbose=0)\n","    features[image] = feature"]},{"cell_type":"code","execution_count":147,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T02:18:58.575445Z","iopub.status.busy":"2023-12-15T02:18:58.574992Z","iopub.status.idle":"2023-12-15T02:18:58.592915Z","shell.execute_reply":"2023-12-15T02:18:58.591987Z","shell.execute_reply.started":"2023-12-15T02:18:58.575411Z"},"trusted":true},"outputs":[],"source":["class CustomDataGenerator(Sequence):\n","    \n","    def __init__(self, df, X_col, y_col, batch_size, directory, tokenizer, \n","                 vocab_size, max_length, features,shuffle=True):\n","    \n","        self.df = df.copy()\n","        self.X_col = X_col\n","        self.y_col = y_col\n","        self.directory = directory\n","        self.batch_size = batch_size\n","        self.tokenizer = tokenizer\n","        self.vocab_size = vocab_size\n","        self.max_length = max_length\n","        self.features = features\n","        self.shuffle = shuffle\n","        self.n = len(self.df)\n","        \n","    def on_epoch_end(self):\n","        if self.shuffle:\n","            self.df = self.df.sample(frac=1).reset_index(drop=True)\n","    \n","    def __len__(self):\n","        return self.n // self.batch_size\n","    \n","    def __getitem__(self,index):\n","    \n","        batch = self.df.iloc[index * self.batch_size:(index + 1) * self.batch_size,:]\n","        X1, X2, y = self.__get_data(batch)        \n","        return (X1, X2), y\n","    \n","    def __get_data(self,batch):\n","        \n","        X1, X2, y = list(), list(), list()\n","        \n","        images = batch[self.X_col].tolist()\n","           \n","        for image in images:\n","            feature = self.features[image][0]\n","            \n","            captions = batch.loc[batch[self.X_col]==image, self.y_col].tolist()\n","            for caption in captions:\n","                seq = self.tokenizer.texts_to_sequences([caption])[0]\n","\n","                for i in range(1,len(seq)):\n","                    in_seq, out_seq = seq[:i], seq[i]\n","                    in_seq = pad_sequences([in_seq], maxlen=self.max_length)[0]\n","                    out_seq = to_categorical([out_seq], num_classes=self.vocab_size)[0]\n","                    X1.append(feature)\n","                    X2.append(in_seq)\n","                    y.append(out_seq)\n","            \n","        X1, X2, y = np.array(X1), np.array(X2), np.array(y)\n","                \n","        return X1, X2, y"]},{"cell_type":"code","execution_count":148,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T02:19:00.435583Z","iopub.status.busy":"2023-12-15T02:19:00.435159Z","iopub.status.idle":"2023-12-15T02:19:00.736769Z","shell.execute_reply":"2023-12-15T02:19:00.736048Z","shell.execute_reply.started":"2023-12-15T02:19:00.435550Z"},"trusted":true},"outputs":[],"source":["input1 = Input(shape=(1920,))\n","input2 = Input(shape=(max_length,))\n","\n","img_features = Dense(256, activation='relu')(input1)\n","img_features_reshaped = Reshape((1, 256), input_shape=(256,))(img_features)\n","\n","sentence_features = Embedding(vocab_size, 256, mask_zero=False)(input2)\n","merged = concatenate([img_features_reshaped,sentence_features],axis=1)\n","sentence_features = LSTM(256)(merged)\n","x = Dropout(0.5)(sentence_features)\n","x = add([x, img_features])\n","x = Dense(128, activation='relu')(x)\n","x = Dropout(0.5)(x)\n","output = Dense(vocab_size, activation='softmax')(x)\n","\n","caption_model = Model(inputs=[input1,input2], outputs=output)\n","caption_model.compile(loss='categorical_crossentropy',optimizer='adam')"]},{"cell_type":"code","execution_count":149,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T02:19:01.483163Z","iopub.status.busy":"2023-12-15T02:19:01.482314Z","iopub.status.idle":"2023-12-15T02:19:01.487264Z","shell.execute_reply":"2023-12-15T02:19:01.486326Z","shell.execute_reply.started":"2023-12-15T02:19:01.483129Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.utils import plot_model"]},{"cell_type":"code","execution_count":151,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T02:19:03.736465Z","iopub.status.busy":"2023-12-15T02:19:03.736010Z","iopub.status.idle":"2023-12-15T02:19:03.744614Z","shell.execute_reply":"2023-12-15T02:19:03.743732Z","shell.execute_reply.started":"2023-12-15T02:19:03.736427Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_12\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_19 (InputLayer)           [(None, 1920)]       0                                            \n","__________________________________________________________________________________________________\n","dense_18 (Dense)                (None, 256)          491776      input_19[0][0]                   \n","__________________________________________________________________________________________________\n","input_20 (InputLayer)           [(None, 74)]         0                                            \n","__________________________________________________________________________________________________\n","reshape_6 (Reshape)             (None, 1, 256)       0           dense_18[0][0]                   \n","__________________________________________________________________________________________________\n","embedding_6 (Embedding)         (None, 74, 256)      4689664     input_20[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate_6 (Concatenate)     (None, 75, 256)      0           reshape_6[0][0]                  \n","                                                                 embedding_6[0][0]                \n","__________________________________________________________________________________________________\n","lstm_6 (LSTM)                   (None, 256)          525312      concatenate_6[0][0]              \n","__________________________________________________________________________________________________\n","dropout_12 (Dropout)            (None, 256)          0           lstm_6[0][0]                     \n","__________________________________________________________________________________________________\n","add_6 (Add)                     (None, 256)          0           dropout_12[0][0]                 \n","                                                                 dense_18[0][0]                   \n","__________________________________________________________________________________________________\n","dense_19 (Dense)                (None, 128)          32896       add_6[0][0]                      \n","__________________________________________________________________________________________________\n","dropout_13 (Dropout)            (None, 128)          0           dense_19[0][0]                   \n","__________________________________________________________________________________________________\n","dense_20 (Dense)                (None, 18319)        2363151     dropout_13[0][0]                 \n","==================================================================================================\n","Total params: 8,102,799\n","Trainable params: 8,102,799\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["caption_model.summary()"]},{"cell_type":"code","execution_count":223,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T03:59:53.289786Z","iopub.status.busy":"2023-12-15T03:59:53.288823Z","iopub.status.idle":"2023-12-15T03:59:53.295359Z","shell.execute_reply":"2023-12-15T03:59:53.294473Z","shell.execute_reply.started":"2023-12-15T03:59:53.289737Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(135080, 3)"]},"execution_count":223,"metadata":{},"output_type":"execute_result"}],"source":["train.shape"]},{"cell_type":"code","execution_count":153,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T02:19:12.990551Z","iopub.status.busy":"2023-12-15T02:19:12.990121Z","iopub.status.idle":"2023-12-15T02:19:13.012299Z","shell.execute_reply":"2023-12-15T02:19:13.011529Z","shell.execute_reply.started":"2023-12-15T02:19:12.990516Z"},"trusted":true},"outputs":[],"source":["train_generator = CustomDataGenerator(df=train,X_col='image_name',y_col='comment',batch_size=64,directory=image_path,\n","                                      tokenizer=tokenizer,vocab_size=vocab_size,max_length=max_length,features=features)\n","\n","validation_generator = CustomDataGenerator(df=test,X_col='image_name',y_col='comment',batch_size=64,directory=image_path,\n","                                      tokenizer=tokenizer,vocab_size=vocab_size,max_length=max_length,features=features)"]},{"cell_type":"code","execution_count":154,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T02:19:16.215417Z","iopub.status.busy":"2023-12-15T02:19:16.214921Z","iopub.status.idle":"2023-12-15T02:19:16.230845Z","shell.execute_reply":"2023-12-15T02:19:16.229996Z","shell.execute_reply.started":"2023-12-15T02:19:16.215378Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image_name</th>\n","      <th>comment_number</th>\n","      <th>comment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>544301311.jpg</td>\n","      <td>0</td>\n","      <td>startseq two women with white head garb and lo...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>544301311.jpg</td>\n","      <td>1</td>\n","      <td>startseq two women in traditional european dre...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>544301311.jpg</td>\n","      <td>2</td>\n","      <td>startseq the women sit outside on the steps re...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>544301311.jpg</td>\n","      <td>3</td>\n","      <td>startseq two women in period dress sitting in ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>544301311.jpg</td>\n","      <td>4</td>\n","      <td>startseq two girls sit by doorway on the steps...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>23830</th>\n","      <td>998845445.jpg</td>\n","      <td>0</td>\n","      <td>startseq man in shorts and hawaiian shirt lean...</td>\n","    </tr>\n","    <tr>\n","      <th>23831</th>\n","      <td>998845445.jpg</td>\n","      <td>1</td>\n","      <td>startseq young man hanging over the side of bo...</td>\n","    </tr>\n","    <tr>\n","      <th>23832</th>\n","      <td>998845445.jpg</td>\n","      <td>2</td>\n","      <td>startseq man is leaning off of the side of blu...</td>\n","    </tr>\n","    <tr>\n","      <th>23833</th>\n","      <td>998845445.jpg</td>\n","      <td>3</td>\n","      <td>startseq man riding small boat in harbor with ...</td>\n","    </tr>\n","    <tr>\n","      <th>23834</th>\n","      <td>998845445.jpg</td>\n","      <td>4</td>\n","      <td>startseq man on moored blue and white boat wit...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>23835 rows × 3 columns</p>\n","</div>"],"text/plain":["          image_name  comment_number  \\\n","0      544301311.jpg               0   \n","1      544301311.jpg               1   \n","2      544301311.jpg               2   \n","3      544301311.jpg               3   \n","4      544301311.jpg               4   \n","...              ...             ...   \n","23830  998845445.jpg               0   \n","23831  998845445.jpg               1   \n","23832  998845445.jpg               2   \n","23833  998845445.jpg               3   \n","23834  998845445.jpg               4   \n","\n","                                                 comment  \n","0      startseq two women with white head garb and lo...  \n","1      startseq two women in traditional european dre...  \n","2      startseq the women sit outside on the steps re...  \n","3      startseq two women in period dress sitting in ...  \n","4      startseq two girls sit by doorway on the steps...  \n","...                                                  ...  \n","23830  startseq man in shorts and hawaiian shirt lean...  \n","23831  startseq young man hanging over the side of bo...  \n","23832  startseq man is leaning off of the side of blu...  \n","23833  startseq man riding small boat in harbor with ...  \n","23834  startseq man on moored blue and white boat wit...  \n","\n","[23835 rows x 3 columns]"]},"execution_count":154,"metadata":{},"output_type":"execute_result"}],"source":["test"]},{"cell_type":"code","execution_count":155,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T02:19:17.164136Z","iopub.status.busy":"2023-12-15T02:19:17.163215Z","iopub.status.idle":"2023-12-15T02:19:17.171109Z","shell.execute_reply":"2023-12-15T02:19:17.170155Z","shell.execute_reply.started":"2023-12-15T02:19:17.164096Z"},"trusted":true},"outputs":[],"source":["model_name = \"model.pkl\"\n","checkpoint = ModelCheckpoint(model_name,\n","                            monitor=\"val_loss\",\n","                            mode=\"min\",\n","                            save_best_only = True,\n","                            verbose=1)\n","\n","earlystopping = EarlyStopping(monitor='val_loss',min_delta = 0, patience = 5, verbose = 1, restore_best_weights=True)\n","\n","learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', \n","                                            patience=3, \n","                                            verbose=1, \n","                                            factor=0.2, \n","                                            min_lr=0.00000001)"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":157,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T03:11:02.161749Z","iopub.status.busy":"2023-12-15T03:11:02.161307Z","iopub.status.idle":"2023-12-15T03:42:06.710583Z","shell.execute_reply":"2023-12-15T03:42:06.709641Z","shell.execute_reply.started":"2023-12-15T03:11:02.161712Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","2110/2110 [==============================] - 380s 180ms/step - loss: 3.8086 - val_loss: 4.0645\n","\n","Epoch 00001: val_loss improved from 4.09365 to 4.06447, saving model to model.pkl\n","Epoch 2/5\n","2110/2110 [==============================] - 375s 178ms/step - loss: 3.7671 - val_loss: 4.0704\n","\n","Epoch 00002: val_loss did not improve from 4.06447\n","Epoch 3/5\n","2110/2110 [==============================] - 374s 177ms/step - loss: 3.7352 - val_loss: 4.0690\n","\n","Epoch 00003: val_loss did not improve from 4.06447\n","Epoch 4/5\n","2110/2110 [==============================] - 345s 164ms/step - loss: 3.7089 - val_loss: 4.0717\n","\n","Epoch 00004: val_loss did not improve from 4.06447\n","\n","Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n","Epoch 5/5\n","2110/2110 [==============================] - 379s 180ms/step - loss: 3.6266 - val_loss: 4.0493\n","\n","Epoch 00005: val_loss improved from 4.06447 to 4.04928, saving model to model.pkl\n"]}],"source":["history = caption_model.fit(\n","        train_generator,\n","        epochs=5,\n","        validation_data=validation_generator,\n","        callbacks=[checkpoint,earlystopping,learning_rate_reduction])"]},{"cell_type":"code","execution_count":159,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T03:42:14.754746Z","iopub.status.busy":"2023-12-15T03:42:14.754347Z","iopub.status.idle":"2023-12-15T03:42:14.981568Z","shell.execute_reply":"2023-12-15T03:42:14.980349Z","shell.execute_reply.started":"2023-12-15T03:42:14.754711Z"},"trusted":true},"outputs":[],"source":["caption_model.save('caption_model.h5')  # Saves the model in HDF5 format\n"]},{"cell_type":"code","execution_count":160,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T03:42:17.967600Z","iopub.status.busy":"2023-12-15T03:42:17.967196Z","iopub.status.idle":"2023-12-15T03:42:17.972490Z","shell.execute_reply":"2023-12-15T03:42:17.971638Z","shell.execute_reply.started":"2023-12-15T03:42:17.967568Z"},"trusted":true},"outputs":[],"source":["def idx_to_word(integer,tokenizer):\n","    \n","    for word, index in tokenizer.word_index.items():\n","        if index==integer:\n","            return word\n","    return None"]},{"cell_type":"code","execution_count":208,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T03:55:51.101559Z","iopub.status.busy":"2023-12-15T03:55:51.101096Z","iopub.status.idle":"2023-12-15T03:55:51.108924Z","shell.execute_reply":"2023-12-15T03:55:51.108000Z","shell.execute_reply.started":"2023-12-15T03:55:51.101523Z"},"trusted":true},"outputs":[],"source":["def predict_caption(model, image, tokenizer, max_length, features):\n","    \n","    feature = features[image]\n","    in_text = \"startseq\"\n","    for i in range(max_length):\n","        sequence = tokenizer.texts_to_sequences([in_text])[0]\n","        sequence = pad_sequences([sequence], max_length)\n","\n","        y_pred = model.predict([feature,sequence])\n","        y_pred = np.argmax(y_pred)\n","        \n","        word = idx_to_word(y_pred, tokenizer)\n","        \n","        if word is None:\n","            break\n","            \n","        in_text+= \" \" + word\n","        \n","        if word == 'endseq':\n","            break\n","            \n","    return in_text "]},{"cell_type":"code","execution_count":209,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T03:55:53.413090Z","iopub.status.busy":"2023-12-15T03:55:53.412637Z","iopub.status.idle":"2023-12-15T03:55:53.419740Z","shell.execute_reply":"2023-12-15T03:55:53.418972Z","shell.execute_reply.started":"2023-12-15T03:55:53.413037Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(23835, 3)"]},"execution_count":209,"metadata":{},"output_type":"execute_result"}],"source":["test.shape"]},{"cell_type":"markdown","metadata":{},"source":["## **Taking 15 Random Samples for Caption Prediction**"]},{"cell_type":"code","execution_count":210,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T03:55:54.260174Z","iopub.status.busy":"2023-12-15T03:55:54.259780Z","iopub.status.idle":"2023-12-15T03:55:54.266220Z","shell.execute_reply":"2023-12-15T03:55:54.265315Z","shell.execute_reply.started":"2023-12-15T03:55:54.260142Z"},"trusted":true},"outputs":[],"source":["samples = test.sample(10)\n","samples.reset_index(drop=True,inplace=True)"]},{"cell_type":"code","execution_count":211,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T03:55:54.937630Z","iopub.status.busy":"2023-12-15T03:55:54.937237Z","iopub.status.idle":"2023-12-15T03:55:58.851908Z","shell.execute_reply":"2023-12-15T03:55:58.851010Z","shell.execute_reply.started":"2023-12-15T03:55:54.937600Z"},"trusted":true},"outputs":[],"source":["for index,record in samples.iterrows():\n","\n","    img = load_img(os.path.join(image_path,record['image_name']),target_size=(224,224))\n","    img = img_to_array(img)\n","    img = img/255.\n","    \n","    caption = predict_caption(caption_model, record['image_name'], tokenizer, max_length, features)\n","    samples.loc[index,'comment'] = caption"]},{"cell_type":"code","execution_count":226,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T04:15:39.579930Z","iopub.status.busy":"2023-12-15T04:15:39.579354Z","iopub.status.idle":"2023-12-15T04:15:39.584744Z","shell.execute_reply":"2023-12-15T04:15:39.583834Z","shell.execute_reply.started":"2023-12-15T04:15:39.579895Z"},"trusted":true},"outputs":[],"source":["samples_bleu = test[:1000]\n","samples_bleu.reset_index(drop=True,inplace=True)"]},{"cell_type":"code","execution_count":227,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T04:15:40.642693Z","iopub.status.busy":"2023-12-15T04:15:40.642099Z","iopub.status.idle":"2023-12-15T04:22:53.327720Z","shell.execute_reply":"2023-12-15T04:22:53.326968Z","shell.execute_reply.started":"2023-12-15T04:15:40.642651Z"},"trusted":true},"outputs":[],"source":["actual, predicted = [], []\n","for index,record in samples_bleu.iterrows():\n","\n","    img = load_img(os.path.join(image_path,record['image_name']),target_size=(224,224))\n","    img = img_to_array(img)\n","    img = img/255.\n","    actual_captions = record['comment']\n","    caption = predict_caption(caption_model, record['image_name'], tokenizer, max_length, features)\n","    actual.append(actual_captions)\n","    predicted.append(caption)"]},{"cell_type":"code","execution_count":228,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T04:23:28.296368Z","iopub.status.busy":"2023-12-15T04:23:28.295925Z","iopub.status.idle":"2023-12-15T04:23:28.302699Z","shell.execute_reply":"2023-12-15T04:23:28.301887Z","shell.execute_reply.started":"2023-12-15T04:23:28.296331Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['startseq two women with white head garb and long dresses sitting in front of door on steps reading and drinking beverage endseq',\n"," 'startseq two women in traditional european dress sit on stoop one drinking the other reading endseq',\n"," 'startseq the women sit outside on the steps reading and drinking endseq',\n"," 'startseq two women in period dress sitting in doorway endseq',\n"," 'startseq two girls sit by doorway on the steps endseq',\n"," 'startseq three backpackers one in the foreground and two in the background hike in the wilderness during snowstorm endseq',\n"," 'startseq there are people on snowy mountain and they are hiking with ski poles endseq',\n"," 'startseq trio of people are hiking throughout heavily snowed path endseq',\n"," 'startseq group of hikers on top snowy mountain during storm endseq',\n"," 'startseq three people hiking up mountain in blizzard endseq',\n"," 'startseq man wearing pilot uniform is bending over towards suitcase outside of set of steps leading into plane endseq',\n"," 'startseq pilot is putting his luggage right next to the plane in the airport endseq',\n"," 'startseq an airline flight crew member stands by the steps to an airliner endseq',\n"," 'startseq pilot bends over to carry luggage outside of an airplane endseq',\n"," 'startseq pilot exits stationary airplane endseq']"]},"execution_count":228,"metadata":{},"output_type":"execute_result"}],"source":["actual[:15]"]},{"cell_type":"code","execution_count":229,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T04:23:29.106088Z","iopub.status.busy":"2023-12-15T04:23:29.105343Z","iopub.status.idle":"2023-12-15T04:23:29.111942Z","shell.execute_reply":"2023-12-15T04:23:29.111158Z","shell.execute_reply.started":"2023-12-15T04:23:29.106053Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['startseq woman in black shirt and white pants is sitting on bench endseq',\n"," 'startseq woman in black shirt and white pants is sitting on bench endseq',\n"," 'startseq woman in black shirt and white pants is sitting on bench endseq',\n"," 'startseq woman in black shirt and white pants is sitting on bench endseq',\n"," 'startseq woman in black shirt and white pants is sitting on bench endseq',\n"," 'startseq man in red jacket is standing on snowy hill endseq',\n"," 'startseq man in red jacket is standing on snowy hill endseq',\n"," 'startseq man in red jacket is standing on snowy hill endseq',\n"," 'startseq man in red jacket is standing on snowy hill endseq',\n"," 'startseq man in red jacket is standing on snowy hill endseq',\n"," 'startseq man in blue shirt is working on the roof of building endseq',\n"," 'startseq man in blue shirt is working on the roof of building endseq',\n"," 'startseq man in blue shirt is working on the roof of building endseq',\n"," 'startseq man in blue shirt is working on the roof of building endseq',\n"," 'startseq man in blue shirt is working on the roof of building endseq']"]},"execution_count":229,"metadata":{},"output_type":"execute_result"}],"source":["predicted[:15]"]},{"cell_type":"code","execution_count":230,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T04:23:39.643003Z","iopub.status.busy":"2023-12-15T04:23:39.642201Z","iopub.status.idle":"2023-12-15T04:23:50.908969Z","shell.execute_reply":"2023-12-15T04:23:50.908163Z","shell.execute_reply.started":"2023-12-15T04:23:39.642968Z"},"trusted":true},"outputs":[],"source":["from nltk.translate.bleu_score import corpus_bleu\n","bleu_score = corpus_bleu(actual, predicted)"]},{"cell_type":"code","execution_count":231,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T04:23:50.910709Z","iopub.status.busy":"2023-12-15T04:23:50.910380Z","iopub.status.idle":"2023-12-15T04:23:50.915502Z","shell.execute_reply":"2023-12-15T04:23:50.914708Z","shell.execute_reply.started":"2023-12-15T04:23:50.910681Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0.7244108886576387\n"]}],"source":["print(bleu_score)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":31296,"sourceId":39911,"sourceType":"datasetVersion"},{"datasetId":623289,"sourceId":1111676,"sourceType":"datasetVersion"},{"datasetId":2808179,"sourceId":4845244,"sourceType":"datasetVersion"}],"dockerImageVersionId":30198,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
